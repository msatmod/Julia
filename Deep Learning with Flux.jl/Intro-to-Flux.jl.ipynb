{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaComputing/JuliaAcademyData.jl`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "┌ Error: curl_easy_setopt: 48\n",
      "└ @ Downloads.Curl /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Downloads/src/Curl/utils.jl:36\n",
      "┌ Error: curl_easy_setopt: 48\n",
      "└ @ Downloads.Curl /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Downloads/src/Curl/utils.jl:36\n",
      "┌ Error: curl_easy_setopt: 48\n",
      "└ @ Downloads.Curl /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Downloads/src/Curl/utils.jl:36\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/.julia/packages/JuliaAcademyData/3C2GY/courses/Deep learning with Flux/Project.toml`\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[33m  ✓ \u001b[39m\u001b[90mJSON\u001b[39m\n",
      "\u001b[33m  ✓ \u001b[39m\u001b[90mConda\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFFTW\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFFTViews\u001b[39m\n",
      "\u001b[91m  ✗ \u001b[39m\u001b[90mZygote\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCategoricalArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mImageFiltering\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mImages\n",
      "\u001b[32m  ✓ \u001b[39mDataFrames\n",
      "\u001b[32m  ✓ \u001b[39mCSV\n",
      "\u001b[32m  ✓ \u001b[39mPlots\n",
      "  10 dependencies successfully precompiled in 45 seconds (90 already precompiled, 4 skipped during auto due to previous errors)\n",
      "  \u001b[33m2\u001b[39m dependencies precompiled but different versions are currently loaded. Restart julia to access the new versions\n",
      "  \u001b[91m1\u001b[39m dependency errored. To see a full report either run `import Pkg; Pkg.precompile()` or load the package\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.add(Pkg.PackageSpec(url=\"https://github.com/JuliaComputing/JuliaAcademyData.jl\"))\n",
    "using JuliaAcademyData; activate(\"Deep learning with Flux\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[33m  ✓ \u001b[39m\u001b[90mJSON\u001b[39m\n",
      "\u001b[33m  ✓ \u001b[39m\u001b[90mConda\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFFTW\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFFTViews\u001b[39m\n",
      "\u001b[91m  ✗ \u001b[39m\u001b[90mZygote\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "Pkg.precompile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "# Intro to Flux.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous course, we learned how machine learning allows us to classify data as apples or bananas with a single neuron. However, some of those details are pretty fiddly! Fortunately, Julia has a powerful package that does much of the heavy lifting for us, called [`Flux.jl`](https://fluxml.github.io/).\n",
    "\n",
    "*Using `Flux` will make classifying data and images much easier!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `Flux.jl`\n",
    "\n",
    "We can get started with `Flux.jl` via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "Unsatisfiable requirements detected for package \u001b[38;5;14mCuArrays [3a865a2d]\u001b[39m:\n \u001b[38;5;14mCuArrays [3a865a2d]\u001b[39m log:\n ├─possible versions are: \u001b[38;5;14m0.2.1-2.2.2\u001b[39m or uninstalled\n ├─restricted by compatibility requirements with \u001b[38;5;2mFlux [587475ba]\u001b[39m to versions: \u001b[38;5;14m1.4.3-1.7.3\u001b[39m\n │ └─\u001b[38;5;2mFlux [587475ba]\u001b[39m log:\n │   ├─possible versions are: \u001b[38;5;2m0.4.1-0.12.8\u001b[39m or uninstalled\n │   └─restricted to versions \u001b[38;5;2m0.10.1\u001b[39m by an explicit requirement, leaving only versions \u001b[38;5;2m0.10.1\u001b[39m\n └─restricted by julia compatibility requirements to versions: uninstalled — no versions left",
     "output_type": "error",
     "traceback": [
      "Unsatisfiable requirements detected for package \u001b[38;5;14mCuArrays [3a865a2d]\u001b[39m:\n \u001b[38;5;14mCuArrays [3a865a2d]\u001b[39m log:\n ├─possible versions are: \u001b[38;5;14m0.2.1-2.2.2\u001b[39m or uninstalled\n ├─restricted by compatibility requirements with \u001b[38;5;2mFlux [587475ba]\u001b[39m to versions: \u001b[38;5;14m1.4.3-1.7.3\u001b[39m\n │ └─\u001b[38;5;2mFlux [587475ba]\u001b[39m log:\n │   ├─possible versions are: \u001b[38;5;2m0.4.1-0.12.8\u001b[39m or uninstalled\n │   └─restricted to versions \u001b[38;5;2m0.10.1\u001b[39m by an explicit requirement, leaving only versions \u001b[38;5;2m0.10.1\u001b[39m\n └─restricted by julia compatibility requirements to versions: uninstalled — no versions left",
      "",
      "Stacktrace:",
      "  [1] propagate_constraints!(graph::Pkg.Resolve.Graph, sources::Set{Int64}; log_events::Bool)",
      "    @ Pkg.Resolve /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Resolve/graphtype.jl:1048",
      "  [2] propagate_constraints! (repeats 2 times)",
      "    @ /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Resolve/graphtype.jl:989 [inlined]",
      "  [3] simplify_graph!(graph::Pkg.Resolve.Graph, sources::Set{Int64}; clean_graph::Bool)",
      "    @ Pkg.Resolve /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Resolve/graphtype.jl:1503",
      "  [4] simplify_graph! (repeats 2 times)",
      "    @ /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Resolve/graphtype.jl:1503 [inlined]",
      "  [5] resolve_versions!(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec})",
      "    @ Pkg.Operations /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:408",
      "  [6] targeted_resolve(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}, preserve::Pkg.Types.PreserveLevel)",
      "    @ Pkg.Operations /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1214",
      "  [7] tiered_resolve(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec})",
      "    @ Pkg.Operations /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1200",
      "  [8] _resolve",
      "    @ /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1220 [inlined]",
      "  [9] add(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}, new_git::Vector{Base.UUID}; preserve::Pkg.Types.PreserveLevel, platform::Base.BinaryPlatforms.Platform)",
      "    @ Pkg.Operations /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Pkg/src/Operations.jl:1235",
      " [10] add(ctx::Pkg.Types.Context, pkgs::Vector{Pkg.Types.PackageSpec}; preserve::Pkg.Types.PreserveLevel, platform::Base.BinaryPlatforms.Platform, kwargs::Base.Iterators.Pairs{Symbol, IJulia.IJuliaStdio{Base.PipeEndpoint}, Tuple{Symbol}, NamedTuple{(:io,), Tuple{IJulia.IJuliaStdio{Base.PipeEndpoint}}}})",
      "    @ Pkg.API /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:204",
      " [11] add(pkgs::Vector{Pkg.Types.PackageSpec}; io::IJulia.IJuliaStdio{Base.PipeEndpoint}, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ Pkg.API /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:80",
      " [12] add(pkgs::Vector{Pkg.Types.PackageSpec})",
      "    @ Pkg.API /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:78",
      " [13] #add#23",
      "    @ /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:76 [inlined]",
      " [14] add",
      "    @ /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:76 [inlined]",
      " [15] #add#22",
      "    @ /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:75 [inlined]",
      " [16] add(pkg::String)",
      "    @ Pkg.API /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Pkg/src/API.jl:75",
      " [17] top-level scope",
      "    @ In[3]:3",
      " [18] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [19] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "# using Pkg; Pkg.add([\"Flux\", \"Plots\"])\n",
    "using Pkg\n",
    "\n",
    "Pkg.add(\"Flux\")\n",
    "Pkg.add(\"Zygote\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpful built-in functions\n",
    "\n",
    "When working we'll `Flux`, we'll make use of built-in functionality that we've had to create for ourselves in previous notebooks.\n",
    "\n",
    "For example, the sigmoid function, σ, that we have been using already lives within `Flux`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\u001b[36mσ\u001b[39m\" can be typed by \u001b[36m\\sigma<tab>\u001b[39m\n",
      "\n",
      "search:\n",
      "\n",
      "Couldn't find \u001b[36mσ\u001b[39m\n",
      "Perhaps you meant !, %, &, ', *, +, -, /, :, <, >, \\, ^, |, ~, ÷, π, ℯ, ∈ or ∉\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "No documentation found.\n",
       "\n",
       "Binding \\texttt{σ} does not exist.\n",
       "\n"
      ],
      "text/markdown": [
       "No documentation found.\n",
       "\n",
       "Binding `σ` does not exist.\n"
      ],
      "text/plain": [
       "  No documentation found.\n",
       "\n",
       "  Binding \u001b[36mσ\u001b[39m does not exist."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: plot not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: plot not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[6]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "plot(σ, -5, 5, label=\"\\\\sigma\", xlabel=\"x\", ylabel=\"\\\\sigma\\\\(x\\\\)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, `Flux` allows us to *automatically create neurons* with the **`Dense`** function. For example, in the last notebook, we were looking at a neuron with 2 inputs and 1 output:\n",
    "\n",
    " <img src=\"https://raw.githubusercontent.com/JuliaComputing/JuliaAcademyData.jl/master/courses/Deep%20learning%20with%20Flux/data/single-neuron.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    " We could create a neuron with two inputs and one output via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Dense(2, 1, σ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `model` object comes with places to store weights and biases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(model.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rand(2)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "σ.(model.W*x + model.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike in previous notebooks, note that `W` is no longer a `Vector` (1D `Array`) and `b` is no longer a number! Both are now stored in so-called `TrackedArray`s and `W` is effectively being treated as a matrix with a single row. We'll see why below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other helpful built-in functionality includes ways to automatically calculate gradients and also the cost function that we've used in the previous course -\n",
    "\n",
    "$$L(w, b) = \\sum_i \\left[y_i - f(x_i, w, b) \\right]^2$$\n",
    "\n",
    "If you normalize by dividing by the total number of elements, this becomes the \"mean square error\" function, which in `Flux` is named **`Flux.mse`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods(Flux.mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing it all together\n",
    "\n",
    "Load the datasets that contain the features of the apple and banana images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames\n",
    "\n",
    "apples = DataFrame(CSV.File(datapath(\"data/apples.dat\"), delim='\\t', allowmissing=:none, normalizenames=true))\n",
    "bananas = DataFrame(CSV.File(datapath(\"data/bananas.dat\"), delim='\\t', allowmissing=:none, normalizenames=true));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_apples  = [ [row.red, row.green] for row in eachrow(apples)]\n",
    "x_bananas = [ [row.red, row.green] for row in eachrow(bananas)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the x (features) together to create a vector of all our datapoints, and create the corresponding vector of known labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [x_apples; x_bananas]\n",
    "ys = [fill(0, size(x_apples)); fill(1, size(x_bananas))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Dense(2, 1, σ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the model (currently initialized with random weights) to see what the output value is for a given input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(xs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course we can examine the current loss value for that datapoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Flux.mse(model(xs[1]), ys[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux.Tracker\n",
    "back!(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the tools necessary to build a simple gradient descent algorithm!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The easy way\n",
    "\n",
    "You don't want to manually write out gradient descent algorithms every time! Flux, of course, also brings in lots of optimizers that can do this all for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?Flux.train!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can simply define our loss function, an optimizer, and then call `train!`. That's basic machine learning with Flux.jl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Dense(2, 1, σ)\n",
    "L(x,y) = Flux.mse(model(x), y)\n",
    "opt = SGD(params(model))\n",
    "Flux.train!(L, zip(xs, ys), opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour(0:.1:1, 0:.1:1, (x, y) -> model([x,y])[].data, fill=true)\n",
    "scatter!(first.(x_apples), last.(x_apples), label=\"apples\")\n",
    "scatter!(first.(x_bananas), last.(x_bananas), label=\"bananas\")\n",
    "xlabel!(\"mean red value\")\n",
    "ylabel!(\"mean green value\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
